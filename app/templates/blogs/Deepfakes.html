{% extends "blogs/blogs_template.html" %}
{% block fb_share_url %}http://inwaitoftomorrow.appspot.com/blogs/Deepfakes{% endblock %}
{% block fb_share_description %}'Deepfakes' could improve the lives of thousands who suffer from speech impairments, but could they be the biggest threat to democracy?{% endblock %}
{% block fb_share_image %}'http://inwaitoftomorrow.appspot.com/static/img/Deepfakes.png'{% endblock %}
{% block twitter_share_description %}'Deepfakes' could improve the lives of thousands who suffer from speech impairments, but could they be the biggest threat to democracy?{% endblock %}
{% block twitter_share_image %}'http://inwaitoftomorrow.appspot.com/static/img/Deepfakes.png'{% endblock %}
{% block twitter_share_url %}http://inwaitoftomorrow.appspot.com/blogs/Deepfakes{% endblock %}
{% block meta_description %}Deepfake technology is a subset of artificial intelligence (AI). People can creat ultra-realistic media from very little samples using machine learning.{% endblock %}
{% block title %}Are ‘deepfakes’ our biggest threat to democracy?{% endblock %}
{% block img_src %}{% endblock %}
{% block image_header_tw0 %}'../static/img/Deepfakes.png'{% endblock %}
{% block header %}Are ‘deepfakes’ our biggest threat to democracy?{% endblock %}
{% block article_title %}Are ‘deepfakes’ our biggest threat to democracy?{% endblock %}
{% block main_article %}
    <div id="intro" class="align-items-center justify-content-center pt-2">
        <h4 class="h4 font-weight-bold" style="min-width: 100%">What are deepfakes?</h4>
        <p>Deepfakes have seen huge development in recent years. Deepfakes are amazingly realistic pieces of media generated by deep learning AI. The AI is given data, perhaps in the form of a video recording showcasing a person’s face and voice, and is able to create synthetic media of that person doing or saying something that they haven’t.</p>
        <p>There have already been cases of Deepfakes being used to create fake celebrity pornographic videos, fake news and hoaxes.</p>
        <p>At this moment, we can usually tell when something is a deepfake, but they are becoming alarmingly realistic. </p>
        <p>The rate at which this technology advances is amazing and it can potentially do some incredible things.</p>
        <iframe width="100%" height="400" class="align-self-center" src="https://www.youtube.com/embed/DFrJv-eJb64">
        </iframe>
        <a href="#section2" class="align-items-center align-content-center align-self-center" style="padding-left: 50%"><i class="arrow down"></i></a>
    </div>
    <div id="section2">
        <h4 class="h4 font-weight-bold">Deepfakes can be used to help people with neurodegenerative diseases</h4>
        <p>Like all AI, deepfakes have huge potential, particularly in the medical field. In January, The US Federal Trade Commission hosted a seminar which highlighted the promise of voice cloning, a subcategory of deepfake technology.</p>
        <p>At the seminar, John Costello, the director of Boston Children’s Hospital’s augmentative communication program, advocated the use of voice cloning. The technology could give those with Amyotrophic Lateral Sclerosis (ALS – also known as motor neurone disease), Huntington’s disease and autism the ability to speak.</p>
        <p>ALS is a neurodegenerative disease that takes away one’s ability to control certain voluntary muscles. Muscles gradually get weaker and there is uncontrollable twitching and loss of speech amongst many other complications. From onset, the average survival rate is around two to four years, although Stephen Hawking famously lived for over 50 years after onset.</p>
        <p>Lyrebird is a company which has developed voice cloning technology for years. From a small audio file sample, they can create a digital voice that sounds exactly like you. There are around 1500 new cases of ALS diagnosed each year. This technology has the power to improve these lives, plus the lives of people with Huntington’s disease, autism and those with other speech impairments.</p>
        <a href="#section3" class="align-self-center" style="padding-left: 50%"><i class="arrow down"></i></a>
    </div>
    <div id="section3">
        <h4 class="h4 font-weight-bold">The threat to democracy</h4>
        <p>This new technology could give an entirely new dimension to fake news and has the potential to ruin reputations. Russia is at the forefront of the disinformation controversy, particularly since their interference in the 2016 US elections. As to whether Russia will interfere with the following election, “There is little to no doubt that Russia’s digital disinformation conglomerate has people working on deepfakes,” says the director of the Transatlantic Commission on Election Integrity, Eileen Donahoe.</p>
        <p>YouTube page ‘derpfakes’ has been persistently uploading videos of different celebrities which have been created using deepfake technology. They recently created a deepfake video of Donald Trump, using one of Alec Baldwin’s famous impressions of the US president.</p>
        <iframe width="100%" height="400" class="align-self-center" src="https://www.youtube.com/embed/hoc2RISoLWU">
        </iframe>
        <a href="#section4" class="align-self-center" style="padding-left: 50%"><i class="arrow down"></i></a>
    </div>
    <div id="section4">
        <h4 class="h4 font-weight-bold">How do we rise to the challenge?</h4>
        <p>Faculty is a tech start-up based in Marylebone, London, which is close to University College London (UCL) since many of the employees are UCL graduates. Faculty has been exploring deepfakes by analysing all the known techniques that are used to create them. The aim is to create a library of deepfake techniques which, they say, will help train systems to distinguish between a deepfake and a real video. Essentially, they’re creating and training AI systems to detect deepfakes.</p>
        <p>New York-based company Amber also talk about a ‘fingerprinting’ software aimed to be installed to all smartphone cameras. At the time of recording, the video is fingerprinted. The fingerprint of the video when the recording is played back can be compared to the original fingerprint. This will provide a score which can indicate the likelihood of any tampering.</p>
        <p>Despite all the effort against deepfakes, people are always going to use them to try and spread misinformation. Currently, there are ways of spotting deepfakes. Alexander Adam, an analyst at Faculty, described common flaws such as a lack of blinking, a face wobble or distortion and strange behaviour.</p>
        <a href="#intro" class="align-self-center">Return to top</a>
    </div>

<div class="pb-3">
<!-- hitwebcounter Code START -->
<a href="https://www.hitwebcounter.com" target="_blank">
<img src="https://hitwebcounter.com/counter/counter.php?page=7212165&style=0032&nbdigits=5&type=page&initCount=0" title="User Stats" Alt="webcounterwebsite"   border="0" >
</a>

</div>
{% endblock %}
{% block time_and_date %}<p>Dillon Lad - 21/03/2020</p>{% endblock %}
{% block comments_fb_share %}http://inwaitoftomorrow.appspot.com/blogs/Deepfakes{% endblock %}

{% block comments_fb %}http://inwaitoftomorrow.appspot.com/blogs/Deepfakes{% endblock %}